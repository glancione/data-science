{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55c7b79a",
   "metadata": {},
   "source": [
    "# Exercises - Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34fa4e4",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd23d34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use(style = 'seaborn')\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "runCVflag = False # If False then optimal values are used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda34a62",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdae372",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## You can retrieve the data at https://www.kaggle.com/c/ieee-fraud-detection/data \n",
    "data_path = \"./\"\n",
    "train_tr = pd.read_csv(data_path + \"train_transaction.csv\")\n",
    "train_id = pd.read_csv(data_path + \"train_identity.csv\") \n",
    "test_tr = pd.read_csv(data_path + \"test_transaction.csv\")\n",
    "test_id = pd.read_csv(data_path + \"test_identity.csv\")\n",
    "\n",
    "print('train_transaction shape is: {}'.format(train_tr.shape))\n",
    "print('train_identity shape is: {}'.format(train_id.shape))\n",
    "\n",
    "print('test_transaction shape is: {}'.format(test_tr.shape))\n",
    "print('test_identity shape is: {}'.format(test_id.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7e8bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42e4d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36c8002",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce742372",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed61238",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a795fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train = pd.merge(train_tr, train_id, how = 'left', on = 'TransactionID')\n",
    "test = pd.merge(test_tr, test_id, how = 'left', on = 'TransactionID')\n",
    "del train_tr, train_id, test_tr, test_id\n",
    "print('train set shape is: {}'.format(train.shape))\n",
    "print('test set shape is: {}'.format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf69ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e2904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adec5654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def different_columns(traincols, testcols):\n",
    "    diff_cols = []\n",
    "    for i in traincols:\n",
    "        if i not in testcols:\n",
    "            diff_cols.append(i)\n",
    "    return diff_cols\n",
    "            \n",
    "print(different_columns(train.columns, test.columns))\n",
    "# train and test sets should have the same columns (not considering the target variable 'IsFraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b34cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.rename(columns = {\"id-01\": \"id_01\", \"id-02\": \"id_02\", \"id-03\": \"id_03\", \n",
    "                            \"id-06\": \"id_06\", \"id-05\": \"id_05\", \"id-04\": \"id_04\", \n",
    "                            \"id-07\": \"id_07\", \"id-08\": \"id_08\", \"id-09\": \"id_09\", \n",
    "                            \"id-10\": \"id_10\", \"id-11\": \"id_11\", \"id-12\": \"id_12\", \n",
    "                            \"id-15\": \"id_15\", \"id-14\": \"id_14\", \"id-13\": \"id_13\", \n",
    "                            \"id-16\": \"id_16\", \"id-17\": \"id_17\", \"id-18\": \"id_18\", \n",
    "                            \"id-21\": \"id_21\", \"id-20\": \"id_20\", \"id-19\": \"id_19\", \n",
    "                            \"id-22\": \"id_22\", \"id-23\": \"id_23\", \"id-24\": \"id_24\", \n",
    "                            \"id-27\": \"id_27\", \"id-26\": \"id_26\", \"id-25\": \"id_25\", \n",
    "                            \"id-28\": \"id_28\", \"id-29\": \"id_29\", \"id-30\": \"id_30\", \n",
    "                            \"id-31\": \"id_31\", \"id-32\": \"id_32\", \"id-33\": \"id_33\", \n",
    "                            \"id-34\": \"id_34\", \"id-35\": \"id_35\", \"id-36\": \"id_36\", \n",
    "                            \"id-37\": \"id_37\", \"id-38\": \"id_38\"})\n",
    "\n",
    "print(different_columns(train.columns, test.columns))\n",
    "# now test and train have the same column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5756097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (5, 5))\n",
    "sns.barplot(x = [0,1], y = train['isFraud'].value_counts().values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860b7343",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_ratio = train['isFraud'].sum()/len(train['isFraud'])\n",
    "print(fraud_ratio) # percentage of frauds in the train set\n",
    "del fraud_ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3694dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_missing_value = train.isnull().sum().sum()\n",
    "print(tot_missing_value) # missing values in the train set\n",
    "del tot_missing_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ecb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_missing_value = train.isnull().sum()\n",
    "print(column_missing_value[0 : 60])\n",
    "print(column_missing_value[60 : 120])\n",
    "print(column_missing_value[120 : 180])\n",
    "print(column_missing_value[180 : 240])\n",
    "print(column_missing_value[240 : 300])\n",
    "print(column_missing_value[300 : 360])\n",
    "print(column_missing_value[360 : 420])\n",
    "print(column_missing_value[420 : 434])\n",
    "del column_missing_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b95efe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLOT TRANSACTION DATES (THEY DON'T OVERLAP) \n",
    "\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "plt.hist(train['TransactionDT'], label = 'Train', color = 'red')\n",
    "plt.hist(test['TransactionDT'], label = 'Test', color = 'yellow')\n",
    "plt.legend()\n",
    "plt.title('Train vs. Test TransactionDT Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630149f2",
   "metadata": {},
   "source": [
    "## Variables Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbf671a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "encoder_dict = {}\n",
    "\n",
    "complete_labelset_temp = pd.concat([train.drop(['isFraud'], axis=1), test], axis=0).reset_index()\n",
    "variables_encode = complete_labelset_temp.keys()\n",
    "for k in variables_encode:\n",
    "    if complete_labelset_temp[k].dtype == object:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le_fit = le.fit(complete_labelset_temp[k])\n",
    "        encoder_dict.update({k: le_fit})\n",
    "        #train[k + '_encoded'] = le_fit.transform(train[k])  \n",
    "        train[k + '_encoded'] = encoder_dict[k].transform(train[k])  \n",
    "        train = train.drop([k], axis=1)\n",
    "        test[k + '_encoded'] = encoder_dict[k].transform(test[k])  \n",
    "        test = test.drop([k], axis=1)\n",
    "\n",
    "del complete_labelset_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94555bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bab27e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90858070",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train_set shape is: {}'.format(train.shape))\n",
    "print('test_set shape is: {}'.format(test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955a22a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (5, 5))\n",
    "sns.barplot(x = [0,1], y = train['isFraud'].value_counts().values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e267530",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_ratio = train['isFraud'].sum()/len(train['isFraud'])\n",
    "print(fraud_ratio) # percentage of frauds in the train set\n",
    "del fraud_ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1aaa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = pd.DataFrame(columns = ['train_time', 'train_precision', 'train_accuracy', 'train_recall', 'train_roc_auc',\n",
    "                                   'test_precision', 'test_accuracy', 'test_recall', 'test_roc_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576def23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metric_stats(experiment_name, y_train, y_train_pred, y_test, y_pred):\n",
    "    print('-----------------------------------------------------')\n",
    "    print(experiment_name + ' train precision score is {}'.format(precision_score(y_train, y_train_pred)))\n",
    "    print(experiment_name + ' train accuracy score is {}'.format(accuracy_score(y_train, y_train_pred)))\n",
    "    print(experiment_name + ' train recall score is {}'.format(recall_score(y_train, y_train_pred)))\n",
    "    print(experiment_name + ' train auc score is {}'.format(roc_auc_score(y_train, y_train_pred)))\n",
    "    print('-----------------------------------------------------')\n",
    "    print(experiment_name + ' test precision score is {}'.format(precision_score(y_test, y_pred)))\n",
    "    print(experiment_name + ' test accuracy score is {}'.format(accuracy_score(y_test, y_pred)))\n",
    "    print(experiment_name + ' test recall score is {}'.format(recall_score(y_test, y_pred)))\n",
    "    print(experiment_name + ' test auc score is {}'.format(roc_auc_score(y_test, y_pred)))\n",
    "    print('-----------------------------------------------------')\n",
    "    print(' Train confusion matrix')\n",
    "    print(confusion_matrix(y_train, y_train_pred))\n",
    "    print('-----------------------------------------------------')\n",
    "    print(' Test confusion matrix')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print('-----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f17f603",
   "metadata": {},
   "source": [
    "## Unbalanced Approach - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d59f684",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start_time = datetime.datetime.now()\n",
    "experiment_name = 'UNBALANCED APPROACH - DECISION TREE'\n",
    "\n",
    "X = train.copy()\n",
    "y = train['isFraud'].copy()\n",
    "X = X.drop(['isFraud'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17, shuffle=False)\n",
    "\n",
    "# Create our imputer to replace missing values with the mean e.g.\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp = imp.fit(X_train)\n",
    "\n",
    "# Impute our data, then train\n",
    "X_train_imp = imp.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62f1b81",
   "metadata": {},
   "source": [
    "### Random Search Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ced6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if runCVflag:\n",
    "    clf_model = DecisionTreeClassifier(criterion=\"gini\")\n",
    "    distrib = dict(max_depth = [10,100,500], min_samples_leaf=[5,10,20,50])\n",
    "    clf = RandomizedSearchCV(clf_model, distrib, random_state=17)\n",
    "    search = clf.fit(X_train_imp,y_train)\n",
    "    best_min_samples_leaf = search.best_params_['min_samples_leaf']\n",
    "    best_max_depth = search.best_params_['max_depth']\n",
    "else:\n",
    "    # results ====> optimal values are: 'min_samples_leaf': 20, 'max_depth': 10\n",
    "    best_min_samples_leaf = 20\n",
    "    best_max_depth = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c84ef01",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55392c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf_model = DecisionTreeClassifier(criterion=\"gini\", max_depth = best_max_depth, min_samples_leaf = best_min_samples_leaf)\n",
    "clf_model.fit(X_train_imp,y_train)\n",
    "end_time = datetime.datetime.now() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dbbb0e",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408bff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = []\n",
    "X_test_imp = imp.transform(X_test)\n",
    "y_pred = clf_model.predict(X_test_imp)\n",
    "y_train_pred = clf_model.predict(X_train_imp)\n",
    "\n",
    "stats_df.loc[experiment_name] = ([end_time,\n",
    "                                  precision_score(y_train, y_train_pred),\n",
    "                                  accuracy_score(y_train, y_train_pred),\n",
    "                                  recall_score(y_train, y_train_pred),\n",
    "                                  roc_auc_score(y_train, y_train_pred),\n",
    "                                  precision_score(y_test, y_pred),\n",
    "                                  accuracy_score(y_test, y_pred),\n",
    "                                  recall_score(y_test, y_pred),\n",
    "                                  roc_auc_score(y_test, y_pred),\n",
    "                                 ])\n",
    "\n",
    "print_metric_stats(experiment_name, y_train, y_train_pred, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36f58e6",
   "metadata": {},
   "source": [
    "## Unbalanced Approach - Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c9be6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start_time = datetime.datetime.now()\n",
    "experiment_name = 'UNBALANCED APPROACH - XGBOOST'\n",
    "\n",
    "X = train.copy()\n",
    "y = train['isFraud'].copy()\n",
    "X = X.drop(['isFraud'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17, shuffle=False)\n",
    "\n",
    "# Create our imputer to replace missing values with the mean e.g.\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp = imp.fit(X_train)\n",
    "\n",
    "# Impute our data, then train\n",
    "X_train_imp = imp.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47208ee",
   "metadata": {},
   "source": [
    "### Random Search Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c29791",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if runCVflag:\n",
    "    clf_model = xgb.XGBClassifier(tree_method = 'gpu_hist')\n",
    "    distrib = dict(max_depth = [5,10], n_estimators = [50, 100], learning_rate=[0.02, 0.1, 0.2])\n",
    "    clf = RandomizedSearchCV(clf_model, distrib, random_state=17)\n",
    "    search = clf.fit(X_train_imp,y_train)\n",
    "    best_n_estimators = search.best_params_['n_estimators']\n",
    "    best_max_depth = search.best_params_['max_depth']\n",
    "    best_learning_rate = search.best_params_['learning_rate']\n",
    "else:\n",
    "    # results ====> optimal values are: 'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.02\n",
    "    best_max_depth = 10\n",
    "    best_n_estimators = 100\n",
    "    best_learning_rate = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e04b46",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800e9c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgmodel = xgb.XGBClassifier(tree_method = 'gpu_hist',\n",
    "                            max_depth = best_max_depth,\n",
    "                            n_estimators = best_n_estimators,\n",
    "                            learning_rate = best_learning_rate)\n",
    "\n",
    "xgmodel.fit(X_train_imp,y_train)\n",
    "\n",
    "end_time = datetime.datetime.now() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727667ab",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96e0f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = []\n",
    "X_test_imp = imp.transform(X_test)\n",
    "y_pred = xgmodel.predict(X_test_imp)\n",
    "y_train_pred = xgmodel.predict(X_train_imp)\n",
    "\n",
    "\n",
    "stats_df.loc[experiment_name] = ([end_time,\n",
    "                                  precision_score(y_train, y_train_pred),\n",
    "                                  accuracy_score(y_train, y_train_pred),\n",
    "                                  recall_score(y_train, y_train_pred),\n",
    "                                  roc_auc_score(y_train, y_train_pred),\n",
    "                                  precision_score(y_test, y_pred),\n",
    "                                  accuracy_score(y_test, y_pred),\n",
    "                                  recall_score(y_test, y_pred),\n",
    "                                  roc_auc_score(y_test, y_pred),\n",
    "                                 ])\n",
    "\n",
    "print_metric_stats(experiment_name, y_train, y_train_pred, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992b44ac",
   "metadata": {},
   "source": [
    "## Undersampling Approach - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4ab02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "experiment_name = 'UNDERSAMPLING APPROACH - DECISION TREE'\n",
    "\n",
    "X = train.copy()\n",
    "y = train['isFraud'].copy()\n",
    "X = X.drop(['isFraud'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17, shuffle=False)\n",
    "\n",
    "# Create our imputer to replace missing values with the mean e.g.\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp = imp.fit(X_train)\n",
    "\n",
    "# Impute our data, then train\n",
    "X_train_imp = imp.transform(X_train)\n",
    "\n",
    "# Undersample the train dataset\n",
    "ros = RandomUnderSampler(random_state=17)\n",
    "\n",
    "X_train_imp, y_train = ros.fit_resample(X_train_imp, y_train)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfae0eb4",
   "metadata": {},
   "source": [
    "### Random Search Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c40699",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if runCVflag:\n",
    "    clf_model = DecisionTreeClassifier(criterion=\"gini\")\n",
    "    distrib = dict(max_depth = [10,100,500], min_samples_leaf=[5,10,20,50])\n",
    "    clf = RandomizedSearchCV(clf_model, distrib, random_state=17)\n",
    "    search = clf.fit(X_train_imp,y_train)\n",
    "    best_min_samples_leaf = search.best_params_['min_samples_leaf']\n",
    "    best_max_depth = search.best_params_['max_depth']\n",
    "else:\n",
    "    # results ====> optimal values are: 'min_samples_leaf': 50, 'max_depth': 10\n",
    "    best_min_samples_leaf = 50\n",
    "    best_max_depth = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b443b5",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc678a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf_model = DecisionTreeClassifier(criterion=\"gini\", \n",
    "                                   max_depth = best_max_depth, \n",
    "                                   min_samples_leaf = best_min_samples_leaf)\n",
    "\n",
    "clf_model.fit(X_train_imp,y_train)\n",
    "\n",
    "end_time = datetime.datetime.now() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e482e5",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33f2369",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = []\n",
    "X_test_imp = imp.transform(X_test)\n",
    "y_pred = clf_model.predict(X_test_imp)\n",
    "y_train_pred = clf_model.predict(X_train_imp)\n",
    "\n",
    "\n",
    "\n",
    "stats_df.loc[experiment_name] = ([end_time,\n",
    "                                  precision_score(y_train, y_train_pred),\n",
    "                                  accuracy_score(y_train, y_train_pred),\n",
    "                                  recall_score(y_train, y_train_pred),\n",
    "                                  roc_auc_score(y_train, y_train_pred),\n",
    "                                  precision_score(y_test, y_pred),\n",
    "                                  accuracy_score(y_test, y_pred),\n",
    "                                  recall_score(y_test, y_pred),\n",
    "                                  roc_auc_score(y_test, y_pred),\n",
    "                                 ])\n",
    "\n",
    "print_metric_stats(experiment_name, y_train, y_train_pred, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aa7f89",
   "metadata": {},
   "source": [
    "## Undersampling Approach - Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ae3647",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "experiment_name = 'UNDERSAMPLING APPROACH - XGBOOST'\n",
    "\n",
    "X = train.copy()\n",
    "y = train['isFraud'].copy()\n",
    "X = X.drop(['isFraud'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17, shuffle=False)\n",
    "\n",
    "# Create our imputer to replace missing values with the mean e.g.\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp = imp.fit(X_train)\n",
    "\n",
    "# Impute our data, then train\n",
    "X_train_imp = imp.transform(X_train)\n",
    "\n",
    "# Undersample the train dataset\n",
    "ros = RandomUnderSampler(random_state=17)\n",
    "\n",
    "X_train_imp, y_train = ros.fit_resample(X_train_imp, y_train)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14ca61e",
   "metadata": {},
   "source": [
    "### Random Search Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e54fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if runCVflag:\n",
    "    clf_model = xgb.XGBClassifier(tree_method = 'gpu_hist')\n",
    "    distrib = dict(max_depth = [5,10], n_estimators = [50, 100], learning_rate=[0.02, 0.1, 0.2])\n",
    "    clf = RandomizedSearchCV(clf_model, distrib, random_state=17)\n",
    "    search = clf.fit(X_train_imp,y_train)\n",
    "    best_n_estimators = search.best_params_['n_estimators']\n",
    "    best_max_depth = search.best_params_['max_depth']\n",
    "    best_learning_rate = search.best_params_['learning_rate']\n",
    "else:\n",
    "    # results ====> optimal values are: 'n_estimators': 50, 'max_depth': 5, 'learning_rate': 0.02\n",
    "    best_max_depth = 50\n",
    "    best_n_estimators = 5\n",
    "    best_learning_rate = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6dbcf8",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd83807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgmodel = xgb.XGBClassifier(tree_method = 'gpu_hist',\n",
    "                            max_depth = best_max_depth,\n",
    "                            n_estimators = best_n_estimators,\n",
    "                            learning_rate = best_learning_rate)\n",
    "\n",
    "xgmodel.fit(X_train_imp,y_train)\n",
    "\n",
    "end_time = datetime.datetime.now() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaa5204",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe0a6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = []\n",
    "X_test_imp = imp.transform(X_test)\n",
    "y_pred = xgmodel.predict(X_test_imp)\n",
    "y_train_pred = xgmodel.predict(X_train_imp)\n",
    "\n",
    "\n",
    "stats_df.loc[experiment_name] = ([end_time,\n",
    "                                  precision_score(y_train, y_train_pred),\n",
    "                                  accuracy_score(y_train, y_train_pred),\n",
    "                                  recall_score(y_train, y_train_pred),\n",
    "                                  roc_auc_score(y_train, y_train_pred),\n",
    "                                  precision_score(y_test, y_pred),\n",
    "                                  accuracy_score(y_test, y_pred),\n",
    "                                  recall_score(y_test, y_pred),\n",
    "                                  roc_auc_score(y_test, y_pred),\n",
    "                                 ])\n",
    "\n",
    "print_metric_stats(experiment_name, y_train, y_train_pred, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d816ae5d",
   "metadata": {},
   "source": [
    "## Oversampling Approach - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b44afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "experiment_name = 'OVERSAMPLING APPROACH - DECISION TREE'\n",
    "\n",
    "X = train.copy()\n",
    "y = train['isFraud'].copy()\n",
    "X = X.drop(['isFraud'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17, shuffle=False)\n",
    "\n",
    "# Create our imputer to replace missing values with the mean e.g.\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp = imp.fit(X_train)\n",
    "\n",
    "# Impute our data, then train\n",
    "X_train_imp = imp.transform(X_train)\n",
    "\n",
    "# Undersample the train dataset\n",
    "ros = RandomOverSampler(random_state=17)\n",
    "\n",
    "X_train_imp, y_train = ros.fit_resample(X_train_imp, y_train)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea67ab39",
   "metadata": {},
   "source": [
    "### Random Search Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20277284",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if runCVflag:\n",
    "    clf_model = DecisionTreeClassifier(criterion=\"gini\")\n",
    "    distrib = dict(max_depth = [10,100,500], min_samples_leaf=[5,10,20,50])\n",
    "    clf = RandomizedSearchCV(clf_model, distrib, random_state=17)\n",
    "    search = clf.fit(X_train_imp,y_train)\n",
    "    best_min_samples_leaf = search.best_params_['min_samples_leaf']\n",
    "    best_max_depth = search.best_params_['max_depth']\n",
    "else:\n",
    "    # results ====> optimal values are: 'min_samples_leaf': 5, 'max_depth': 100\n",
    "    best_min_samples_leaf = 5\n",
    "    best_max_depth = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2adf57",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e494001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf_model = DecisionTreeClassifier(criterion=\"gini\", \n",
    "                                   max_depth = best_max_depth, \n",
    "                                   min_samples_leaf = best_min_samples_leaf)\n",
    "\n",
    "clf_model.fit(X_train_imp,y_train)\n",
    "\n",
    "end_time = datetime.datetime.now() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a6b684",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b405048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = []\n",
    "X_test_imp = imp.transform(X_test)\n",
    "y_pred = clf_model.predict(X_test_imp)\n",
    "y_train_pred = clf_model.predict(X_train_imp)\n",
    "\n",
    "\n",
    "stats_df.loc[experiment_name] = ([end_time,\n",
    "                                  precision_score(y_train, y_train_pred),\n",
    "                                  accuracy_score(y_train, y_train_pred),\n",
    "                                  recall_score(y_train, y_train_pred),\n",
    "                                  roc_auc_score(y_train, y_train_pred),\n",
    "                                  precision_score(y_test, y_pred),\n",
    "                                  accuracy_score(y_test, y_pred),\n",
    "                                  recall_score(y_test, y_pred),\n",
    "                                  roc_auc_score(y_test, y_pred),\n",
    "                                 ])\n",
    "\n",
    "print_metric_stats(experiment_name, y_train, y_train_pred, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5480c6f",
   "metadata": {},
   "source": [
    "## Oversampling Approach - Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8708bf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "experiment_name = 'OVERSAMPLING APPROACH - XGBOOST'\n",
    "\n",
    "X = train.copy()\n",
    "y = train['isFraud'].copy()\n",
    "X = X.drop(['isFraud'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17, shuffle=False)\n",
    "\n",
    "# Create our imputer to replace missing values with the mean e.g.\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp = imp.fit(X_train)\n",
    "\n",
    "# Impute our data, then train\n",
    "X_train_imp = imp.transform(X_train)\n",
    "\n",
    "# Undersample the train dataset\n",
    "ros = RandomOverSampler(random_state=17)\n",
    "\n",
    "X_train_imp, y_train = ros.fit_resample(X_train_imp, y_train)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5a25d0",
   "metadata": {},
   "source": [
    "### Random Search Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20bbe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if runCVflag:\n",
    "    clf_model = xgb.XGBClassifier(tree_method = 'gpu_hist')\n",
    "    distrib = dict(max_depth = [5,10], n_estimators = [50, 100], learning_rate=[0.02, 0.1, 0.2])\n",
    "    clf = RandomizedSearchCV(clf_model, distrib, random_state=17)\n",
    "    search = clf.fit(X_train_imp,y_train)\n",
    "    best_n_estimators = search.best_params_['n_estimators']\n",
    "    best_max_depth = search.best_params_['max_depth']\n",
    "    best_learning_rate = search.best_params_['learning_rate']\n",
    "else:\n",
    "    # results ====> optimal values are: 'n_estimators': 5, 'max_depth': 50, 'learning_rate': 0.02\n",
    "    best_max_depth = 5\n",
    "    best_n_estimators = 50\n",
    "    best_learning_rate = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90509eeb",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af495e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgmodel = xgb.XGBClassifier(tree_method = 'gpu_hist',\n",
    "                           max_depth = best_max_depth,\n",
    "                            n_estimators = best_n_estimators,\n",
    "                            learning_rate = best_learning_rate)\n",
    "\n",
    "xgmodel.fit(X_train_imp,y_train)\n",
    "\n",
    "end_time = datetime.datetime.now() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8338a104",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb5a5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = []\n",
    "X_test_imp = imp.transform(X_test)\n",
    "y_pred = xgmodel.predict(X_test_imp)\n",
    "y_train_pred = xgmodel.predict(X_train_imp)\n",
    "\n",
    "\n",
    "stats_df.loc[experiment_name] = ([end_time,\n",
    "                                  precision_score(y_train, y_train_pred),\n",
    "                                  accuracy_score(y_train, y_train_pred),\n",
    "                                  recall_score(y_train, y_train_pred),\n",
    "                                  roc_auc_score(y_train, y_train_pred),\n",
    "                                  precision_score(y_test, y_pred),\n",
    "                                  accuracy_score(y_test, y_pred),\n",
    "                                  recall_score(y_test, y_pred),\n",
    "                                  roc_auc_score(y_test, y_pred),\n",
    "                                 ])\n",
    "\n",
    "print_metric_stats(experiment_name, y_train, y_train_pred, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5738e32",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fae552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(stats_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
