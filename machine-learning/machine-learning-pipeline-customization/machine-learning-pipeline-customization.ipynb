{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7ahcKtM5s3W"
   },
   "source": [
    "# Machine Learning - Pipeline Customization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1d0QRyB5wSP"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 438,
     "status": "ok",
     "timestamp": 1712734640588,
     "user": {
      "displayName": "Gabriele Lancione",
      "userId": "02497574145285887205"
     },
     "user_tz": -120
    },
    "id": "3XY40GZo5olv",
    "outputId": "b12a4724-0a7a-474b-f4f5-324853d36e01"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gabriele/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/gabriele/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/gabriele/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IzrqI-V-51CR"
   },
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1613,
     "status": "ok",
     "timestamp": 1712734644196,
     "user": {
      "displayName": "Gabriele Lancione",
      "userId": "02497574145285887205"
     },
     "user_tz": -120
    },
    "id": "EDLp1RMX5zwy"
   },
   "outputs": [],
   "source": [
    "categories = [\n",
    " 'comp.graphics',\n",
    " 'comp.os.ms-windows.misc',\n",
    " 'rec.sport.baseball',\n",
    " 'rec.sport.hockey',\n",
    " 'alt.atheism',\n",
    " 'soc.religion.christian',\n",
    "]\n",
    "\n",
    "dataset = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, remove=('headers', 'footers', 'quotes'))\n",
    "df = pd.DataFrame(dataset.data, columns=[\"corpus\"]).sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0k6M2er5-my"
   },
   "source": [
    "## Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1712734644196,
     "user": {
      "displayName": "Gabriele Lancione",
      "userId": "02497574145285887205"
     },
     "user_tz": -120
    },
    "id": "hG6LOTyz57gT"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text: str, remove_stopwords: bool) -> str:\n",
    "    text = re.sub(r\"http\\S+\", \"\", text) # removes link\n",
    "    text = re.sub(\"[^A-Za-z]+\", \" \", text) # removes numbers and symbols\n",
    "    if remove_stopwords: # removes stopwords\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        tokens = [w for w in tokens if not w.lower() in stopwords.words(\"english\")]\n",
    "        text = \" \".join(tokens)\n",
    "    text = text.lower().strip() # removes spaces and apply lower case\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_sentiment(text: str):\n",
    "  vader = SentimentIntensityAnalyzer()\n",
    "  return vader.polarity_scores(text)['compound']\n",
    "\n",
    "def get_nchars(text: str): # returns the length of a string\n",
    "  return len(text)\n",
    "\n",
    "def get_nsentences(text: str): # returns number of words in a text\n",
    "  return len(text.split(\".\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnDZm-j-9DO7"
   },
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1712734644198,
     "user": {
      "displayName": "Gabriele Lancione",
      "userId": "02497574145285887205"
     },
     "user_tz": -120
    },
    "id": "oZJvrKfI6mOi"
   },
   "outputs": [],
   "source": [
    "class DummyTransformer(BaseEstimator, TransformerMixin):\n",
    "  def __init__(self):\n",
    "    return None\n",
    "\n",
    "  def fit(self, X=None, y=None):\n",
    "    return self\n",
    "\n",
    "  def transform(self, X=None):\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1712734644537,
     "user": {
      "displayName": "Gabriele Lancione",
      "userId": "02497574145285887205"
     },
     "user_tz": -120
    },
    "id": "6FGVX46K6tFQ"
   },
   "outputs": [],
   "source": [
    "class Preprocessor(DummyTransformer):\n",
    "  def __init__(self, remove_stopwords: bool):\n",
    "    self.remove_stopwords = remove_stopwords\n",
    "    return None\n",
    "  def transform(self, X=None):\n",
    "    preprocessed = X.apply(lambda x: preprocess_text(x, self.remove_stopwords)).values\n",
    "    return preprocessed\n",
    "\n",
    "class SentimentAnalysis(DummyTransformer):\n",
    "  def transform(self, X=None):\n",
    "    sentiment = X.apply(lambda x: get_sentiment(x)).values\n",
    "    return sentiment.reshape(-1, 1) # <-- da notare il reshape per trasformare un vettore riga in uno colonna\n",
    "\n",
    "class NChars(DummyTransformer):\n",
    "  def transform(self, X=None):\n",
    "    n_chars = X.apply(lambda x: get_nchars(x)).values\n",
    "    return n_chars.reshape(-1, 1)\n",
    "\n",
    "class NSententences(DummyTransformer):\n",
    "  def transform(self, X=None):\n",
    "    n_sentences = X.apply(lambda x: get_nsentences(x)).values\n",
    "    return n_sentences.reshape(-1, 1)\n",
    "\n",
    "class FromSparseToArray(DummyTransformer):\n",
    "  def transform(self, X=None):\n",
    "    arr = X.toarray()\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1712734645017,
     "user": {
      "displayName": "Gabriele Lancione",
      "userId": "02497574145285887205"
     },
     "user_tz": -120
    },
    "id": "idtZKy9P68cR"
   },
   "outputs": [],
   "source": [
    "vectorization_pipeline = Pipeline(steps=[\n",
    "    ('preprocess', Preprocessor(remove_stopwords=True)),\n",
    "    ('tfidf_vectorization', TfidfVectorizer()),\n",
    "    ('arr', FromSparseToArray()),\n",
    "    ])\n",
    "# preprocess the text -> tfidf vectorization -> transformation of the vectorization into an array (so that we can put it into a dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1712734645354,
     "user": {
      "displayName": "Gabriele Lancione",
      "userId": "02497574145285887205"
     },
     "user_tz": -120
    },
    "id": "umfV5CNJ7Kl_",
    "outputId": "636408bd-dbe2-4782-c365-cfe206506cc9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>FeatureUnion(transformer_list=[(&#x27;vectorization&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                                                 Preprocessor(remove_stopwords=True)),\n",
       "                                                (&#x27;tfidf_vectorization&#x27;,\n",
       "                                                 TfidfVectorizer()),\n",
       "                                                (&#x27;arr&#x27;, FromSparseToArray())])),\n",
       "                               (&#x27;sentiment&#x27;, SentimentAnalysis()),\n",
       "                               (&#x27;n_chars&#x27;, NChars()),\n",
       "                               (&#x27;n_sentences&#x27;, NSententences())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FeatureUnion</label><div class=\"sk-toggleable__content\"><pre>FeatureUnion(transformer_list=[(&#x27;vectorization&#x27;,\n",
       "                                Pipeline(steps=[(&#x27;preprocess&#x27;,\n",
       "                                                 Preprocessor(remove_stopwords=True)),\n",
       "                                                (&#x27;tfidf_vectorization&#x27;,\n",
       "                                                 TfidfVectorizer()),\n",
       "                                                (&#x27;arr&#x27;, FromSparseToArray())])),\n",
       "                               (&#x27;sentiment&#x27;, SentimentAnalysis()),\n",
       "                               (&#x27;n_chars&#x27;, NChars()),\n",
       "                               (&#x27;n_sentences&#x27;, NSententences())])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>vectorization</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Preprocessor</label><div class=\"sk-toggleable__content\"><pre>Preprocessor(remove_stopwords=True)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FromSparseToArray</label><div class=\"sk-toggleable__content\"><pre>FromSparseToArray()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>sentiment</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SentimentAnalysis</label><div class=\"sk-toggleable__content\"><pre>SentimentAnalysis()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>n_chars</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NChars</label><div class=\"sk-toggleable__content\"><pre>NChars()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>n_sentences</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NSententences</label><div class=\"sk-toggleable__content\"><pre>NSententences()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "FeatureUnion(transformer_list=[('vectorization',\n",
       "                                Pipeline(steps=[('preprocess',\n",
       "                                                 Preprocessor(remove_stopwords=True)),\n",
       "                                                ('tfidf_vectorization',\n",
       "                                                 TfidfVectorizer()),\n",
       "                                                ('arr', FromSparseToArray())])),\n",
       "                               ('sentiment', SentimentAnalysis()),\n",
       "                               ('n_chars', NChars()),\n",
       "                               ('n_sentences', NSententences())])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\n",
    "  ('vectorization', vectorization_pipeline), # vectorization of the text into a dataframe\n",
    "  ('sentiment', SentimentAnalysis()), # creation of the sentiment analysis feature\n",
    "  ('n_chars', NChars()), # creation of the nchar feature\n",
    "  ('n_sentences', NSententences()) # creation of the nsentences feature\n",
    "]\n",
    "combined = FeatureUnion(features)\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 499,
     "status": "ok",
     "timestamp": 1712734646653,
     "user": {
      "displayName": "Gabriele Lancione",
      "userId": "02497574145285887205"
     },
     "user_tz": -120
    },
    "id": "FT049wOX7Oww",
    "outputId": "71287b71-a88d-4d0f-ed18-a22ff7daf917"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.18218802e-01, 1.18218802e-01, 0.00000000e+00, ...,\n",
       "        9.49500000e-01, 6.10000000e+02, 5.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        7.09600000e-01, 9.34000000e+02, 1.00000000e+01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        9.78600000e-01, 6.93000000e+02, 7.00000000e+00],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.15529689e-01, ...,\n",
       "        9.72400000e-01, 4.06000000e+02, 5.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        3.15900000e-01, 8.77000000e+02, 2.30000000e+01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        2.73200000e-01, 9.76000000e+02, 5.00000000e+00]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.fit_transform(X=df['corpus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 508,
     "status": "ok",
     "timestamp": 1712734746053,
     "user": {
      "displayName": "Gabriele Lancione",
      "userId": "02497574145285887205"
     },
     "user_tz": -120
    },
    "id": "IVA1cWMo7csz"
   },
   "outputs": [],
   "source": [
    "cols = list(vectorization_pipeline.steps[1][1].get_feature_names_out())+ [\"sentiment\", \"n_chars\", \"n_sentences\"]\n",
    "features_df = pd.DataFrame(combined.transform(df['corpus']), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1712734961397,
     "user": {
      "displayName": "Gabriele Lancione",
      "userId": "02497574145285887205"
     },
     "user_tz": -120
    },
    "id": "vLnq15zN7kOw",
    "outputId": "b281e071-368d-4653-8a62-2ff00f4956a1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absurd</th>\n",
       "      <th>act</th>\n",
       "      <th>actually</th>\n",
       "      <th>adams</th>\n",
       "      <th>administrators</th>\n",
       "      <th>admittedly</th>\n",
       "      <th>adult</th>\n",
       "      <th>agreed</th>\n",
       "      <th>allows</th>\n",
       "      <th>almost</th>\n",
       "      <th>...</th>\n",
       "      <th>worthy</th>\n",
       "      <th>would</th>\n",
       "      <th>wrong</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>n_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.118219</td>\n",
       "      <td>0.118219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.236438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078170</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9495</td>\n",
       "      <td>610.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103508</td>\n",
       "      <td>0.103508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7096</td>\n",
       "      <td>934.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098062</td>\n",
       "      <td>0.194524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9786</td>\n",
       "      <td>693.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.127124</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>447.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.403194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 431 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     absurd       act  actually     adams  administrators  admittedly  adult  \\\n",
       "0  0.118219  0.118219       0.0  0.000000             0.0    0.000000    0.0   \n",
       "1  0.000000  0.000000       0.0  0.000000             0.0    0.103508    0.0   \n",
       "2  0.000000  0.000000       0.0  0.000000             0.0    0.000000    0.0   \n",
       "3  0.000000  0.000000       0.0  0.127124             0.0    0.000000    0.0   \n",
       "4  0.000000  0.000000       0.0  0.000000             0.0    0.000000    0.0   \n",
       "\n",
       "     agreed    allows    almost  ...    worthy     would  wrong       yet  \\\n",
       "0  0.000000  0.000000  0.236438  ...  0.000000  0.078170    0.0  0.000000   \n",
       "1  0.103508  0.103508  0.000000  ...  0.000000  0.000000    0.0  0.000000   \n",
       "2  0.000000  0.000000  0.000000  ...  0.098062  0.194524    0.0  0.000000   \n",
       "3  0.000000  0.000000  0.000000  ...  0.000000  0.084058    0.0  0.108067   \n",
       "4  0.000000  0.000000  0.000000  ...  0.000000  0.000000    0.0  0.000000   \n",
       "\n",
       "       york  young  youth  sentiment  n_chars  n_sentences  \n",
       "0  0.000000    0.0    0.0     0.9495    610.0          5.0  \n",
       "1  0.000000    0.0    0.0     0.7096    934.0         10.0  \n",
       "2  0.000000    0.0    0.0     0.9786    693.0          7.0  \n",
       "3  0.000000    0.0    0.0     0.0516    447.0         15.0  \n",
       "4  0.403194    0.0    0.0     0.0000     68.0          1.0  \n",
       "\n",
       "[5 rows x 431 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features_df.iloc[:, -6:] # truncated output\n",
    "features_df.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPyI6mKeaW34d5TFR3tWin3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
