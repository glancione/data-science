{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f52f0971-d2a6-412c-b4c8-876279654869",
   "metadata": {},
   "source": [
    "# Machine Learning - Image Classification Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51628a77-19c1-4e52-a476-3d93069ba70c",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25fe8b5-c78e-4770-9a13-b4ab6a461f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba1fee-bd24-4424-85cb-1bfdf9d85bb9",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c04a1c-1288-4ea4-ac76-e9d059e3d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data can be found at https://drive.google.com/file/d/1dbcWabr3Xrr4JvuG0VxTiweGzHn-YYvW/view\n",
    "\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "train_data_dir = 'v_data/train'\n",
    "validation_data_dir = 'v_data/test'\n",
    "nb_train_samples =400\n",
    "nb_validation_samples = 100\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "\tinput_shape = (3, img_width, img_height)\n",
    "else:\n",
    "\tinput_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b0a9f7-d3bf-4634-b617-694cea8cdfed",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cfab6c-195a-4dcb-9bea-71a5cc91e884",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_export_flag = False\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (2, 2), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "model.add(Conv2D(32, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "model.add(Conv2D(64, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "\t\t\toptimizer='rmsprop',\n",
    "\t\t\tmetrics=['accuracy'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "\trescale=1. / 255,\n",
    "\tshear_range=0.2,\n",
    "\tzoom_range=0.2,\n",
    "\thorizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "\ttrain_data_dir,\n",
    "\ttarget_size=(img_width, img_height),\n",
    "\tbatch_size=batch_size,\n",
    "\tclass_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "\tvalidation_data_dir,\n",
    "\ttarget_size=(img_width, img_height),\n",
    "\tbatch_size=batch_size,\n",
    "\tclass_mode='binary')\n",
    "\n",
    "model.fit(\n",
    "\ttrain_generator,\n",
    "\tsteps_per_epoch=nb_train_samples // batch_size,\n",
    "\tepochs=epochs,\n",
    "\tvalidation_data=validation_generator,\n",
    "\tvalidation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "if model_export_flag:\n",
    "    model.save_weights('model_saved.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1260f4-c1f8-4e75-957f-43089d7b9d09",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb316a2-6764-47ac-afd1-7a55e23bec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_export_flag:\n",
    "    model = load_model('model_saved.h5')\n",
    " \n",
    "image = load_img('v_data/test/planes/5.jpg', target_size=(224, 224))\n",
    "img = np.array(image)\n",
    "img = img / 255.0\n",
    "img = img.reshape(1,224,224,3)\n",
    "label = model.predict(img)\n",
    "print(\"Predicted Class (0 - Cars , 1- Planes): \", label[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
