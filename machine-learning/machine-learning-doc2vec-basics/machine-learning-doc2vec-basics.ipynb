{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2vhRqaICBNJ"
   },
   "source": [
    "# Machine Learning - Doc2Vec Basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHlt9zeFCF4y"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 456,
     "status": "ok",
     "timestamp": 1711545519279,
     "user": {
      "displayName": "Gabriele Lancione",
      "userId": "02497574145285887205"
     },
     "user_tz": -60
    },
    "id": "xGB4uORYBcXU"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import gensim\n",
    "import smart_open\n",
    "import collections\n",
    "import random\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "So-vFYxBCPON"
   },
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1711545519749,
     "user": {
      "displayName": "Gabriele Lancione",
      "userId": "02497574145285887205"
     },
     "user_tz": -60
    },
    "id": "4p-gKiXOCKrF"
   },
   "outputs": [],
   "source": [
    "test_data_dir = os.path.join(gensim.__path__[0], 'test', 'test_data')\n",
    "lee_train_file = os.path.join(test_data_dir, 'lee_background.cor')\n",
    "lee_test_file = os.path.join(test_data_dir, 'lee.cor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1711545519750,
     "user": {
      "displayName": "Gabriele Lancione",
      "userId": "02497574145285887205"
     },
     "user_tz": -60
    },
    "id": "HMTUn3x5CQfk"
   },
   "outputs": [],
   "source": [
    "def read_corpus(fname, tokens_only=False):\n",
    "    with smart_open.open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            tokens = gensim.utils.simple_preprocess(line)\n",
    "            if tokens_only:\n",
    "                yield tokens\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "\n",
    "train_corpus = list(read_corpus(lee_train_file))\n",
    "test_corpus = list(read_corpus(lee_test_file, tokens_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1711545519750,
     "user": {
      "displayName": "Gabriele Lancione",
      "userId": "02497574145285887205"
     },
     "user_tz": -60
    },
    "id": "4shiqPhWCUGD",
    "outputId": "e2435497-0fac-479b-b66d-0ee0f2d8e836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TaggedDocument(words=['hundreds', 'of', 'people', 'have', 'been', 'forced', 'to', 'vacate', 'their', 'homes', 'in', 'the', 'southern', 'highlands', 'of', 'new', 'south', 'wales', 'as', 'strong', 'winds', 'today', 'pushed', 'huge', 'bushfire', 'towards', 'the', 'town', 'of', 'hill', 'top', 'new', 'blaze', 'near', 'goulburn', 'south', 'west', 'of', 'sydney', 'has', 'forced', 'the', 'closure', 'of', 'the', 'hume', 'highway', 'at', 'about', 'pm', 'aedt', 'marked', 'deterioration', 'in', 'the', 'weather', 'as', 'storm', 'cell', 'moved', 'east', 'across', 'the', 'blue', 'mountains', 'forced', 'authorities', 'to', 'make', 'decision', 'to', 'evacuate', 'people', 'from', 'homes', 'in', 'outlying', 'streets', 'at', 'hill', 'top', 'in', 'the', 'new', 'south', 'wales', 'southern', 'highlands', 'an', 'estimated', 'residents', 'have', 'left', 'their', 'homes', 'for', 'nearby', 'mittagong', 'the', 'new', 'south', 'wales', 'rural', 'fire', 'service', 'says', 'the', 'weather', 'conditions', 'which', 'caused', 'the', 'fire', 'to', 'burn', 'in', 'finger', 'formation', 'have', 'now', 'eased', 'and', 'about', 'fire', 'units', 'in', 'and', 'around', 'hill', 'top', 'are', 'optimistic', 'of', 'defending', 'all', 'properties', 'as', 'more', 'than', 'blazes', 'burn', 'on', 'new', 'year', 'eve', 'in', 'new', 'south', 'wales', 'fire', 'crews', 'have', 'been', 'called', 'to', 'new', 'fire', 'at', 'gunning', 'south', 'of', 'goulburn', 'while', 'few', 'details', 'are', 'available', 'at', 'this', 'stage', 'fire', 'authorities', 'says', 'it', 'has', 'closed', 'the', 'hume', 'highway', 'in', 'both', 'directions', 'meanwhile', 'new', 'fire', 'in', 'sydney', 'west', 'is', 'no', 'longer', 'threatening', 'properties', 'in', 'the', 'cranebrook', 'area', 'rain', 'has', 'fallen', 'in', 'some', 'parts', 'of', 'the', 'illawarra', 'sydney', 'the', 'hunter', 'valley', 'and', 'the', 'north', 'coast', 'but', 'the', 'bureau', 'of', 'meteorology', 'claire', 'richards', 'says', 'the', 'rain', 'has', 'done', 'little', 'to', 'ease', 'any', 'of', 'the', 'hundred', 'fires', 'still', 'burning', 'across', 'the', 'state', 'the', 'falls', 'have', 'been', 'quite', 'isolated', 'in', 'those', 'areas', 'and', 'generally', 'the', 'falls', 'have', 'been', 'less', 'than', 'about', 'five', 'millimetres', 'she', 'said', 'in', 'some', 'places', 'really', 'not', 'significant', 'at', 'all', 'less', 'than', 'millimetre', 'so', 'there', 'hasn', 'been', 'much', 'relief', 'as', 'far', 'as', 'rain', 'is', 'concerned', 'in', 'fact', 'they', 've', 'probably', 'hampered', 'the', 'efforts', 'of', 'the', 'firefighters', 'more', 'because', 'of', 'the', 'wind', 'gusts', 'that', 'are', 'associated', 'with', 'those', 'thunderstorms'], tags=[0]), TaggedDocument(words=['indian', 'security', 'forces', 'have', 'shot', 'dead', 'eight', 'suspected', 'militants', 'in', 'night', 'long', 'encounter', 'in', 'southern', 'kashmir', 'the', 'shootout', 'took', 'place', 'at', 'dora', 'village', 'some', 'kilometers', 'south', 'of', 'the', 'kashmiri', 'summer', 'capital', 'srinagar', 'the', 'deaths', 'came', 'as', 'pakistani', 'police', 'arrested', 'more', 'than', 'two', 'dozen', 'militants', 'from', 'extremist', 'groups', 'accused', 'of', 'staging', 'an', 'attack', 'on', 'india', 'parliament', 'india', 'has', 'accused', 'pakistan', 'based', 'lashkar', 'taiba', 'and', 'jaish', 'mohammad', 'of', 'carrying', 'out', 'the', 'attack', 'on', 'december', 'at', 'the', 'behest', 'of', 'pakistani', 'military', 'intelligence', 'military', 'tensions', 'have', 'soared', 'since', 'the', 'raid', 'with', 'both', 'sides', 'massing', 'troops', 'along', 'their', 'border', 'and', 'trading', 'tit', 'for', 'tat', 'diplomatic', 'sanctions', 'yesterday', 'pakistan', 'announced', 'it', 'had', 'arrested', 'lashkar', 'taiba', 'chief', 'hafiz', 'mohammed', 'saeed', 'police', 'in', 'karachi', 'say', 'it', 'is', 'likely', 'more', 'raids', 'will', 'be', 'launched', 'against', 'the', 'two', 'groups', 'as', 'well', 'as', 'other', 'militant', 'organisations', 'accused', 'of', 'targetting', 'india', 'military', 'tensions', 'between', 'india', 'and', 'pakistan', 'have', 'escalated', 'to', 'level', 'not', 'seen', 'since', 'their', 'war'], tags=[1])]\n"
     ]
    }
   ],
   "source": [
    "print(train_corpus[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1711545519750,
     "user": {
      "displayName": "Gabriele Lancione",
      "userId": "02497574145285887205"
     },
     "user_tz": -60
    },
    "id": "kYPH9NNZCWZT",
    "outputId": "30e9135f-85d3-4c7e-8476-2570594138f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'national', 'executive', 'of', 'the', 'strife', 'torn', 'democrats', 'last', 'night', 'appointed', 'little', 'known', 'west', 'australian', 'senator', 'brian', 'greig', 'as', 'interim', 'leader', 'shock', 'move', 'likely', 'to', 'provoke', 'further', 'conflict', 'between', 'the', 'party', 'senators', 'and', 'its', 'organisation', 'in', 'move', 'to', 'reassert', 'control', 'over', 'the', 'party', 'seven', 'senators', 'the', 'national', 'executive', 'last', 'night', 'rejected', 'aden', 'ridgeway', 'bid', 'to', 'become', 'interim', 'leader', 'in', 'favour', 'of', 'senator', 'greig', 'supporter', 'of', 'deposed', 'leader', 'natasha', 'stott', 'despoja', 'and', 'an', 'outspoken', 'gay', 'rights', 'activist'], ['cash', 'strapped', 'financial', 'services', 'group', 'amp', 'has', 'shelved', 'million', 'plan', 'to', 'buy', 'shares', 'back', 'from', 'investors', 'and', 'will', 'raise', 'million', 'in', 'fresh', 'capital', 'after', 'profits', 'crashed', 'in', 'the', 'six', 'months', 'to', 'june', 'chief', 'executive', 'paul', 'batchelor', 'said', 'the', 'result', 'was', 'solid', 'in', 'what', 'he', 'described', 'as', 'the', 'worst', 'conditions', 'for', 'stock', 'markets', 'in', 'years', 'amp', 'half', 'year', 'profit', 'sank', 'per', 'cent', 'to', 'million', 'or', 'share', 'as', 'australia', 'largest', 'investor', 'and', 'fund', 'manager', 'failed', 'to', 'hit', 'projected', 'per', 'cent', 'earnings', 'growth', 'targets', 'and', 'was', 'battered', 'by', 'falling', 'returns', 'on', 'share', 'markets']]\n"
     ]
    }
   ],
   "source": [
    "print(test_corpus[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1711545519750,
     "user": {
      "displayName": "Gabriele Lancione",
      "userId": "02497574145285887205"
     },
     "user_tz": -60
    },
    "id": "bCNBOZtyCYNC",
    "outputId": "03f91a34-02e3-4a6b-d76c-738f254685c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 16:17:12,146 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w5,mc2,s0.001,t3>', 'datetime': '2024-03-28T16:17:12.146973', 'gensim': '4.3.2', 'python': '3.9.6 (default, Feb  3 2024, 15:58:27) \\n[Clang 15.0.0 (clang-1500.3.9.4)]', 'platform': 'macOS-14.3.1-arm64-arm-64bit', 'event': 'created'}\n",
      "2024-03-28 16:17:12,147 : INFO : collecting all words and their counts\n",
      "2024-03-28 16:17:12,147 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2024-03-28 16:17:12,152 : INFO : collected 6981 word types and 300 unique tags from a corpus of 300 examples and 58152 words\n",
      "2024-03-28 16:17:12,152 : INFO : Creating a fresh vocabulary\n",
      "2024-03-28 16:17:12,160 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 retains 3955 unique words (56.65% of original 6981, drops 3026)', 'datetime': '2024-03-28T16:17:12.160132', 'gensim': '4.3.2', 'python': '3.9.6 (default, Feb  3 2024, 15:58:27) \\n[Clang 15.0.0 (clang-1500.3.9.4)]', 'platform': 'macOS-14.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-03-28 16:17:12,160 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 55126 word corpus (94.80% of original 58152, drops 3026)', 'datetime': '2024-03-28T16:17:12.160643', 'gensim': '4.3.2', 'python': '3.9.6 (default, Feb  3 2024, 15:58:27) \\n[Clang 15.0.0 (clang-1500.3.9.4)]', 'platform': 'macOS-14.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-03-28 16:17:12,169 : INFO : deleting the raw counts dictionary of 6981 items\n",
      "2024-03-28 16:17:12,169 : INFO : sample=0.001 downsamples 46 most-common words\n",
      "2024-03-28 16:17:12,170 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 42390.98914085061 word corpus (76.9%% of prior 55126)', 'datetime': '2024-03-28T16:17:12.170096', 'gensim': '4.3.2', 'python': '3.9.6 (default, Feb  3 2024, 15:58:27) \\n[Clang 15.0.0 (clang-1500.3.9.4)]', 'platform': 'macOS-14.3.1-arm64-arm-64bit', 'event': 'prepare_vocab'}\n",
      "2024-03-28 16:17:12,182 : INFO : estimated required memory for 3955 words and 50 dimensions: 3679500 bytes\n",
      "2024-03-28 16:17:12,182 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'penalty' appeared 4 times in the training corpus.\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40) #word count = 2 in order to discard words with very few occurrences\n",
    "model.build_vocab(train_corpus)\n",
    "print(f\"Word 'penalty' appeared {model.wv.get_vecattr('penalty', 'count')} times in the training corpus.\")\n",
    "\n",
    "## Essentially, the vocabulary is a list (accessible via model.wv.index_to_key) of all of the unique words extracted from the training corpus.\n",
    "## Additional attributes for each word are available using the model.wv.get_vecattr() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SH49CWsGCgTR"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4899,
     "status": "ok",
     "timestamp": 1711545524644,
     "user": {
      "displayName": "Gabriele Lancione",
      "userId": "02497574145285887205"
     },
     "user_tz": -60
    },
    "id": "zgROGD5vCecm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 16:17:12,187 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 3955 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-03-28T16:17:12.187386', 'gensim': '4.3.2', 'python': '3.9.6 (default, Feb  3 2024, 15:58:27) \\n[Clang 15.0.0 (clang-1500.3.9.4)]', 'platform': 'macOS-14.3.1-arm64-arm-64bit', 'event': 'train'}\n",
      "2024-03-28 16:17:12,205 : INFO : EPOCH 0: training on 58152 raw words (42735 effective words) took 0.0s, 2655117 effective words/s\n",
      "2024-03-28 16:17:12,221 : INFO : EPOCH 1: training on 58152 raw words (42654 effective words) took 0.0s, 2809149 effective words/s\n",
      "2024-03-28 16:17:12,237 : INFO : EPOCH 2: training on 58152 raw words (42809 effective words) took 0.0s, 2940036 effective words/s\n",
      "2024-03-28 16:17:12,253 : INFO : EPOCH 3: training on 58152 raw words (42672 effective words) took 0.0s, 2865102 effective words/s\n",
      "2024-03-28 16:17:12,269 : INFO : EPOCH 4: training on 58152 raw words (42627 effective words) took 0.0s, 2830337 effective words/s\n",
      "2024-03-28 16:17:12,285 : INFO : EPOCH 5: training on 58152 raw words (42650 effective words) took 0.0s, 2843476 effective words/s\n",
      "2024-03-28 16:17:12,300 : INFO : EPOCH 6: training on 58152 raw words (42801 effective words) took 0.0s, 2914433 effective words/s\n",
      "2024-03-28 16:17:12,317 : INFO : EPOCH 7: training on 58152 raw words (42677 effective words) took 0.0s, 2934833 effective words/s\n",
      "2024-03-28 16:17:12,333 : INFO : EPOCH 8: training on 58152 raw words (42707 effective words) took 0.0s, 2858233 effective words/s\n",
      "2024-03-28 16:17:12,349 : INFO : EPOCH 9: training on 58152 raw words (42583 effective words) took 0.0s, 2844643 effective words/s\n",
      "2024-03-28 16:17:12,365 : INFO : EPOCH 10: training on 58152 raw words (42825 effective words) took 0.0s, 2767002 effective words/s\n",
      "2024-03-28 16:17:12,381 : INFO : EPOCH 11: training on 58152 raw words (42708 effective words) took 0.0s, 2934006 effective words/s\n",
      "2024-03-28 16:17:12,397 : INFO : EPOCH 12: training on 58152 raw words (42755 effective words) took 0.0s, 2862235 effective words/s\n",
      "2024-03-28 16:17:12,413 : INFO : EPOCH 13: training on 58152 raw words (42750 effective words) took 0.0s, 2927690 effective words/s\n",
      "2024-03-28 16:17:12,429 : INFO : EPOCH 14: training on 58152 raw words (42683 effective words) took 0.0s, 2922267 effective words/s\n",
      "2024-03-28 16:17:12,444 : INFO : EPOCH 15: training on 58152 raw words (42648 effective words) took 0.0s, 2898226 effective words/s\n",
      "2024-03-28 16:17:12,460 : INFO : EPOCH 16: training on 58152 raw words (42604 effective words) took 0.0s, 2868015 effective words/s\n",
      "2024-03-28 16:17:12,476 : INFO : EPOCH 17: training on 58152 raw words (42660 effective words) took 0.0s, 2890203 effective words/s\n",
      "2024-03-28 16:17:12,491 : INFO : EPOCH 18: training on 58152 raw words (42668 effective words) took 0.0s, 2867618 effective words/s\n",
      "2024-03-28 16:17:12,507 : INFO : EPOCH 19: training on 58152 raw words (42647 effective words) took 0.0s, 2852054 effective words/s\n",
      "2024-03-28 16:17:12,523 : INFO : EPOCH 20: training on 58152 raw words (42698 effective words) took 0.0s, 2908765 effective words/s\n",
      "2024-03-28 16:17:12,539 : INFO : EPOCH 21: training on 58152 raw words (42618 effective words) took 0.0s, 2919466 effective words/s\n",
      "2024-03-28 16:17:12,555 : INFO : EPOCH 22: training on 58152 raw words (42830 effective words) took 0.0s, 2843651 effective words/s\n",
      "2024-03-28 16:17:12,570 : INFO : EPOCH 23: training on 58152 raw words (42702 effective words) took 0.0s, 2915401 effective words/s\n",
      "2024-03-28 16:17:12,586 : INFO : EPOCH 24: training on 58152 raw words (42652 effective words) took 0.0s, 2977989 effective words/s\n",
      "2024-03-28 16:17:12,602 : INFO : EPOCH 25: training on 58152 raw words (42689 effective words) took 0.0s, 2915003 effective words/s\n",
      "2024-03-28 16:17:12,618 : INFO : EPOCH 26: training on 58152 raw words (42750 effective words) took 0.0s, 2834113 effective words/s\n",
      "2024-03-28 16:17:12,634 : INFO : EPOCH 27: training on 58152 raw words (42846 effective words) took 0.0s, 2904814 effective words/s\n",
      "2024-03-28 16:17:12,649 : INFO : EPOCH 28: training on 58152 raw words (42657 effective words) took 0.0s, 2887261 effective words/s\n",
      "2024-03-28 16:17:12,665 : INFO : EPOCH 29: training on 58152 raw words (42638 effective words) took 0.0s, 2789631 effective words/s\n",
      "2024-03-28 16:17:12,681 : INFO : EPOCH 30: training on 58152 raw words (42570 effective words) took 0.0s, 2867222 effective words/s\n",
      "2024-03-28 16:17:12,697 : INFO : EPOCH 31: training on 58152 raw words (42718 effective words) took 0.0s, 2841883 effective words/s\n",
      "2024-03-28 16:17:12,713 : INFO : EPOCH 32: training on 58152 raw words (42725 effective words) took 0.0s, 2807969 effective words/s\n",
      "2024-03-28 16:17:12,729 : INFO : EPOCH 33: training on 58152 raw words (42680 effective words) took 0.0s, 2854659 effective words/s\n",
      "2024-03-28 16:17:12,746 : INFO : EPOCH 34: training on 58152 raw words (42642 effective words) took 0.0s, 2786649 effective words/s\n",
      "2024-03-28 16:17:12,762 : INFO : EPOCH 35: training on 58152 raw words (42666 effective words) took 0.0s, 2851489 effective words/s\n",
      "2024-03-28 16:17:12,777 : INFO : EPOCH 36: training on 58152 raw words (42678 effective words) took 0.0s, 2908475 effective words/s\n",
      "2024-03-28 16:17:12,793 : INFO : EPOCH 37: training on 58152 raw words (42693 effective words) took 0.0s, 2928733 effective words/s\n",
      "2024-03-28 16:17:12,808 : INFO : EPOCH 38: training on 58152 raw words (42657 effective words) took 0.0s, 2864384 effective words/s\n",
      "2024-03-28 16:17:12,824 : INFO : EPOCH 39: training on 58152 raw words (42590 effective words) took 0.0s, 2894014 effective words/s\n",
      "2024-03-28 16:17:12,824 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2326080 raw words (1707562 effective words) took 0.6s, 2682310 effective words/s', 'datetime': '2024-03-28T16:17:12.824969', 'gensim': '4.3.2', 'python': '3.9.6 (default, Feb  3 2024, 15:58:27) \\n[Clang 15.0.0 (clang-1500.3.9.4)]', 'platform': 'macOS-14.3.1-arm64-arm-64bit', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1711545524645,
     "user": {
      "displayName": "Gabriele Lancione",
      "userId": "02497574145285887205"
     },
     "user_tz": -60
    },
    "id": "Ef2xK-izCjZV",
    "outputId": "4072b4cb-b990-4e83-d20e-0ef2f01aff17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.28579804e-01 -1.93387255e-01 -1.91703320e-01  2.08844453e-01\n",
      " -6.55727312e-02 -2.23161653e-02  3.55680250e-02  1.42806068e-01\n",
      " -2.45812774e-01 -1.68189570e-01  1.72876731e-01  9.75875705e-02\n",
      " -1.28075397e-02 -2.41612666e-04 -1.42846361e-01 -1.09524399e-01\n",
      "  6.15948327e-02  1.03017479e-01  7.86293373e-02 -1.76768988e-01\n",
      " -1.16573326e-01  4.21345644e-02  1.47841707e-01 -4.29139845e-03\n",
      " -9.70738456e-02  3.80495889e-03 -2.33180165e-01  1.89270023e-02\n",
      " -1.45805091e-01 -2.27556611e-05  4.73222017e-01  4.51947562e-02\n",
      "  1.86542377e-01  1.99952617e-01  2.04876631e-01  2.24792957e-01\n",
      " -9.81401578e-02 -1.50636137e-01 -1.71758890e-01 -3.71105634e-02\n",
      " -7.57913920e-04  5.63901290e-02  4.68456447e-02 -7.22627342e-02\n",
      "  1.40534073e-01 -4.47633639e-02 -1.12327784e-01 -8.34705755e-02\n",
      "  1.09989546e-01  7.46573955e-02]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['only', 'you', 'can', 'prevent', 'forest', 'fires'])\n",
    "print(vector)\n",
    "\n",
    "# Now, we can use the trained model to infer a vector for any piece of text by passing a list of words to the model.infer_vector function.\n",
    "# This vector can then be compared with other vectors via cosine similarity.\n",
    "# Note that infer_vector() does not take a string, but rather a list of string tokens.\n",
    "# tokenized the same way as the words property of original training document objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 8170,
     "status": "ok",
     "timestamp": 1711545532811,
     "user": {
      "displayName": "Gabriele Lancione",
      "userId": "02497574145285887205"
     },
     "user_tz": -60
    },
    "id": "8b6Xxw5KCjv9"
   },
   "outputs": [],
   "source": [
    "## The expectation is that we’ve likely overfit our model (i.e., all of the ranks will be less than 2)\n",
    "\n",
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "\n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1711545532811,
     "user": {
      "displayName": "Gabriele Lancione",
      "userId": "02497574145285887205"
     },
     "user_tz": -60
    },
    "id": "3b_A_e6yCnWV",
    "outputId": "005da0cc-102a-4775-e21c-69ebf51f2ba5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 292, 1: 8})\n"
     ]
    }
   ],
   "source": [
    "counter = collections.Counter(ranks)\n",
    "print(counter)\n",
    "# Basically, greater than 95% of the inferred documents are found to be most similar to itself and about 5% of the time it is mistakenly most similar to another document.\n",
    "# Checking the inferred-vector against a training-vector is a sort of ‘sanity check’ as to whether the model is behaving in a usefully consistent manner, though not a real ‘accuracy’ value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1711545532811,
     "user": {
      "displayName": "Gabriele Lancione",
      "userId": "02497574145285887205"
     },
     "user_tz": -60
    },
    "id": "mdkji8bpCrzX",
    "outputId": "aa2afd1d-c2d8-4557-8587-addee678337f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (299): «australia will take on france in the doubles rubber of the davis cup tennis final today with the tie levelled at wayne arthurs and todd woodbridge are scheduled to lead australia in the doubles against cedric pioline and fabrice santoro however changes can be made to the line up up to an hour before the match and australian team captain john fitzgerald suggested he might do just that we ll make team appraisal of the whole situation go over the pros and cons and make decision french team captain guy forget says he will not make changes but does not know what to expect from australia todd is the best doubles player in the world right now so expect him to play he said would probably use wayne arthurs but don know what to expect really pat rafter salvaged australia davis cup campaign yesterday with win in the second singles match rafter overcame an arm injury to defeat french number one sebastien grosjean in three sets the australian says he is happy with his form it not very pretty tennis there isn too many consistent bounces you are playing like said bit of classic old grass court rafter said rafter levelled the score after lleyton hewitt shock five set loss to nicholas escude in the first singles rubber but rafter says he felt no added pressure after hewitt defeat knew had good team to back me up even if we were down he said knew could win on the last day know the boys can win doubles so even if we were down still feel we are good enough team to win and vice versa they are good enough team to beat us as well»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec<dm/m,d50,n5,w5,mc2,s0.001,t3>:\n",
      "\n",
      "MOST (299, 0.9515225291252136): «australia will take on france in the doubles rubber of the davis cup tennis final today with the tie levelled at wayne arthurs and todd woodbridge are scheduled to lead australia in the doubles against cedric pioline and fabrice santoro however changes can be made to the line up up to an hour before the match and australian team captain john fitzgerald suggested he might do just that we ll make team appraisal of the whole situation go over the pros and cons and make decision french team captain guy forget says he will not make changes but does not know what to expect from australia todd is the best doubles player in the world right now so expect him to play he said would probably use wayne arthurs but don know what to expect really pat rafter salvaged australia davis cup campaign yesterday with win in the second singles match rafter overcame an arm injury to defeat french number one sebastien grosjean in three sets the australian says he is happy with his form it not very pretty tennis there isn too many consistent bounces you are playing like said bit of classic old grass court rafter said rafter levelled the score after lleyton hewitt shock five set loss to nicholas escude in the first singles rubber but rafter says he felt no added pressure after hewitt defeat knew had good team to back me up even if we were down he said knew could win on the last day know the boys can win doubles so even if we were down still feel we are good enough team to win and vice versa they are good enough team to beat us as well»\n",
      "\n",
      "SECOND-MOST (104, 0.7966328263282776): «australian cricket captain steve waugh has supported fast bowler brett lee after criticism of his intimidatory bowling to the south african tailenders in the first test in adelaide earlier this month lee was fined for giving new zealand tailender shane bond an unsportsmanlike send off during the third test in perth waugh says tailenders should not be protected from short pitched bowling these days you re earning big money you ve got responsibility to learn how to bat he said mean there no times like years ago when it was not professional and sort of bowlers code these days you re professional our batsmen work very hard at their batting and expect other tailenders to do likewise meanwhile waugh says his side will need to guard against complacency after convincingly winning the first test by runs waugh says despite the dominance of his side in the first test south africa can never be taken lightly it only one test match out of three or six whichever way you want to look at it so there lot of work to go he said but it nice to win the first battle definitely it gives us lot of confidence going into melbourne you know the big crowd there we love playing in front of the boxing day crowd so that will be to our advantage as well south africa begins four day match against new south wales in sydney on thursday in the lead up to the boxing day test veteran fast bowler allan donald will play in the warm up match and is likely to take his place in the team for the second test south african captain shaun pollock expects much better performance from his side in the melbourne test we still believe that we didn play to our full potential so if we can improve on our aspects the output we put out on the field will be lot better and we still believe we have side that is good enough to beat australia on our day he said»\n",
      "\n",
      "MEDIAN (109, 0.250932902097702): «fire has damaged part of st john the divine cathedral in new york one of the world largest cathedrals new york firefighters battled the blaze for four hours before bringing it under control fire officials say there were no reported injuries but the cathedral gift shop had been badly damaged and the sanctuary suffered some smoke and water damage the fire started at around am on tuesday local time in the church gift shop but around firemen were able to stem the flames spread preventing major damage to the sanctuary itself thick black smoke and bright orange flames had billowed from the immense structure in north western manhattan near the columbia university campus the cause of the fire is as yet unknown firefighter robert savarese who was among the first to enter the church said the main problem was visibility we knew which direction the fire was coming from and we just went toward it he said mr savarese was among group of firemen inside the building when third division deputy chief edward dennehy who was standing outside noticed flames pouring out of the building roof the guys in side thought it was small fire because they could not see through the thick smoke mr dennehy said the ceiling could have collapsed the firefighters battling the blaze inside were pulled out and the fire was subsequently attacked with thick fire hoses from atop tall crane»\n",
      "\n",
      "LEAST (243, -0.09261039644479752): «four afghan factions have reached agreement on an interim cabinet during talks in germany the united nations says the administration which will take over from december will be headed by the royalist anti taliban commander hamed karzai it concludes more than week of negotiations outside bonn and is aimed at restoring peace and stability to the war ravaged country the year old former deputy foreign minister who is currently battling the taliban around the southern city of kandahar is an ally of the exiled afghan king mohammed zahir shah he will serve as chairman of an interim authority that will govern afghanistan for six month period before loya jirga or grand traditional assembly of elders in turn appoints an month transitional government meanwhile united states marines are now reported to have been deployed in eastern afghanistan where opposition forces are closing in on al qaeda soldiers reports from the area say there has been gun battle between the opposition and al qaeda close to the tora bora cave complex where osama bin laden is thought to be hiding in the south of the country american marines are taking part in patrols around the air base they have secured near kandahar but are unlikely to take part in any assault on the city however the chairman of the joint chiefs of staff general richard myers says they are prepared for anything they are prepared for engagements they re robust fighting force and they re absolutely ready to engage if that required he said»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1711545532812,
     "user": {
      "displayName": "Gabriele Lancione",
      "userId": "02497574145285887205"
     },
     "user_tz": -60
    },
    "id": "U9g6zXKeCt5o",
    "outputId": "92ddad29-64c3-4c37-f572-7e7fcbd39f3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Document (171): «drug education campaigns appear to be paying dividends with new figures showing per cent drop in drug related deaths last year according to the australian bureau of statistics people died from drug related causes in the year that figure is substantial drop from when australians died of drug related causes across the states and territories new south wales recorded the biggest decrease the bureau david payne attributes the decline of drug deaths to the heroin drought in some parts of the country better equipped ambulances and emergency wards and above all effective federal and state drug education campaigns they have put lot of money into the program there has been fall and while you can discern trend from that the figures are going in the right way right direction mr payne said»\n",
      "\n",
      "Similar Document (123, 0.721383810043335): «new report has revealed there are fewer young people using homeless services than widely thought the australian institute of health and welfare report shows just over per cent of people aged between and used such services over the past year the main reason for young people seeking assistance was based on family or relationship difficulties the report suggests the older people become the less they use homeless services»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document from the corpus and infer a vector from the model\n",
    "doc_id = random.randint(0, len(train_corpus) - 1)\n",
    "\n",
    "# Compare and print the second-most-similar document\n",
    "print('Train Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "sim_id = second_ranks[doc_id]\n",
    "print('Similar Document {}: «{}»\\n'.format(sim_id, ' '.join(train_corpus[sim_id[0]].words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TMjKm4uC1Fh"
   },
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1711545532812,
     "user": {
      "displayName": "Gabriele Lancione",
      "userId": "02497574145285887205"
     },
     "user_tz": -60
    },
    "id": "ziPY0UcuCzNo",
    "outputId": "d462a8b6-fe95-47bd-9003-2a3a59215bd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Document (11): «intelligence cannot say conclusively that saddam hussein has weapons of mass destruction an information gap that is complicating white house efforts to build support for an attack on saddam iraqi regime the cia has advised top administration officials to assume that iraq has some weapons of mass destruction but the agency has not given president bush smoking gun according to intelligence and administration officials»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec<dm/m,d50,n5,w5,mc2,s0.001,t3>:\n",
      "\n",
      "MOST (75, 0.7714795470237732): «us president george bush has marked the th day of the campaign against terrorism by calling on his allies to freeze the assets of two non us organisations suspected of supporting terrorism one of the groups is based in kashmir the other is alleged to have helped al qaeda develop nuclear weapons president bush says former scientist at pakistan atomic program had established group called utn after assisting osama bin laden network develop nuclear bomb utn claims to serve the hungry and needy of afghanistan but it was the utn that provided information about nuclear weapons to al qaeda he said he also linked kashmiri group to the attack on the indian parliament last week lat is an extremist group based in kashmir and is stateless sponsor of terrorism he said mr bush says the international financial crackdown has frozen million in terrorist assets»\n",
      "\n",
      "MEDIAN (211, 0.32493793964385986): «gunman has died after he went on shooting rampage that left another person dead and several more people wounded at factory in goshen indiana officials said the gunman was found dead at the scene but it not clear whether the suspect shot himself elkhart county sheriff department said in statement officials said second person was killed and several more were wounded the shooter was fired from nu wood decorative millwork factory after getting into fight around lunchtime thursday local time and threatened to return with gun the wife of one employee told wndu television four victims were taken to goshen general hospital shortly after the incident began around pm am aedt hospital spokeswoman donna rohrer said three of them were being evaluated for their injuries fourth casualty was airlifted to hospital in fort wayne indiana she said police were unable to enter the factory for over one hour but witnesses told cnn that crack police squads eventually made their way in around pm»\n",
      "\n",
      "LEAST (52, -0.18990565836429596): «skippers are expecting spectacular start to the th sydney to hobart yacht race today with the weather bureau forecasting spinnaker friendly westerly winds total of entrants are in this year race including eight round the world yachts which are expected to give last year line honours winner swedish maxi nicorette run for its money the round the world yachts are set for flying beginning with metre headstart designed to get them out of harm way the boats will have to round buoy further north near sydney heads to equalise the distance ludde ingvall the skipper of nicorette says the split start could help the maxis next year split starts are good and maybe next year they will move all the big boats into the front line so that we can get away without hitting somebody he said skipper ingvall says his start tactics are easy at the start it easy don break and don collide and don go around and don make yourself look silly he said the new south wales weather bureau says there is possibility of waves of up to five metres in bass strait for this year sydney to hobart yacht race severe weather forecaster ken batt says if low pressure system develops more off tasmania the worst case scenario could be strong winds and large seas as the yachts hit the stronger winds in bass strait you be looking at say four to five metre significant wave heights mr batt said»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document from the test corpus and infer a vector from the model\n",
    "doc_id = random.randint(0, len(test_corpus) - 1)\n",
    "inferred_vector = model.infer_vector(test_corpus[doc_id])\n",
    "sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "\n",
    "# Compare and print the most/median/least similar documents from the train corpus\n",
    "print('Test Document ({}): «{}»\\n'.format(doc_id, ' '.join(test_corpus[doc_id])))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMoejB28w8VH9oQPg+OuNya",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
